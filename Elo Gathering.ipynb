{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ddd8a8-d354-4932-aec1-46a1c560bd95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archives fetched successfully.\n",
      "                                                url  \\\n",
      "0      https://www.chess.com/game/live/129497550571   \n",
      "1      https://www.chess.com/game/live/129528141897   \n",
      "2      https://www.chess.com/game/live/129528177563   \n",
      "3      https://www.chess.com/game/live/129528193199   \n",
      "4      https://www.chess.com/game/live/129528760385   \n",
      "...                                             ...   \n",
      "13112    https://www.chess.com/game/live/5922245430   \n",
      "13113    https://www.chess.com/game/live/6049736009   \n",
      "13114    https://www.chess.com/game/live/6050243208   \n",
      "13115    https://www.chess.com/game/live/6050422007   \n",
      "13116    https://www.chess.com/game/live/6050505823   \n",
      "\n",
      "                                                     pgn time_control  \\\n",
      "0      [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...           60   \n",
      "1      [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          180   \n",
      "2      [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          180   \n",
      "3      [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          180   \n",
      "4      [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          180   \n",
      "...                                                  ...          ...   \n",
      "13112  [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          600   \n",
      "13113  [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...           60   \n",
      "13114  [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          600   \n",
      "13115  [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          600   \n",
      "13116  [Event \"Live Chess\"]\\n[Site \"Chess.com\"]\\n[Dat...          600   \n",
      "\n",
      "         end_time  rated                                                tcn  \\\n",
      "0      1735758518   True  lBZJbs!TcD6Lnv0SoELUpF3NEMTZmu5QftUtdt2Uec70iq...   \n",
      "1      1735789237   True  mC0Kbs5QfA9IdE2UEv1TgmQ0ltYQcuIRegRYvwZJCJQJAH...   \n",
      "2      1735789360   True         mC0Kbs!TnDZJDKTCdvCsjs5QfH9Igm7FvwFClB6EHt   \n",
      "3      1735789698   True  lBZJgv!TkA6Lbs0SiqYQcM90mu3VMT0TpFL3ft3tdtWOec...   \n",
      "4      1735789781   True  mC!Tbs5QlB0SCKTJgvJsjs90fHWOHtZRegRKvKQKBK8!nD...   \n",
      "...           ...    ...                                                ...   \n",
      "13112  1607491985   True  lBWGgv3NmC?3bs!VcuXPdl5OecYQCK0SftVEt3EuluNFvF...   \n",
      "13113  1608840054   True  mC0Kbs5Qgv!TlBTCBJQzsCzJdJ9zkszsjsYQJK70K20Ccu...   \n",
      "13114  1608844797   True  lBZJbs5QmC6Snv!TftQztHSZHZ7Zgm86cD0SDKTNmD2UDN...   \n",
      "13115  1608846901   True  mC0Kgv5QlBKBvB9Iks!0blZJCJ7Jlv0LdtLBsBIBvBQBtA...   \n",
      "13116  1608848087   True  lBZJgv5Qks0KmuKBsB!0bs2UsHWOHs92cl8!oE6EpxEvdv...   \n",
      "\n",
      "                                       uuid  \\\n",
      "0      7f291e0f-c873-11ef-82f6-6cfe544c0428   \n",
      "1      a9cfe1a8-c8ba-11ef-82f6-6cfe544c0428   \n",
      "2      565539c4-c8bb-11ef-82f6-6cfe544c0428   \n",
      "3      a1a04768-c8bb-11ef-82f6-6cfe544c0428   \n",
      "4      6a413585-c8bc-11ef-82f6-6cfe544c0428   \n",
      "...                                     ...   \n",
      "13112  9f76dfda-39df-11eb-afcf-0069e4010001   \n",
      "13113  87127c3d-4622-11eb-9c8f-0069e4010001   \n",
      "13114  2866a45c-462d-11eb-9c8f-0069e4010001   \n",
      "13115  f3e7c7a7-4630-11eb-9c8f-0069e4010001   \n",
      "13116  c2bff120-4632-11eb-9c8f-0069e4010001   \n",
      "\n",
      "                                           initial_setup  \\\n",
      "0      rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "1      rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "2      rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "3      rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "4      rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "...                                                  ...   \n",
      "13112  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "13113  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "13114  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "13115  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "13116  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   \n",
      "\n",
      "                                                     fen time_class  ...  \\\n",
      "0                        8/8/8/8/3P4/1KP5/2R5/R3k3 b - -     bullet  ...   \n",
      "1                      6k1/pp6/8/8/5p2/4n2K/5b2/7r w - -      blitz  ...   \n",
      "2      r3k2r/ppp2ppp/2n5/2bpP3/3Pq1b1/2PB2Q1/P1P1N1PP...      blitz  ...   \n",
      "3                       5KQ1/6pk/7p/7P/6P1/2b5/8/8 b - -      blitz  ...   \n",
      "4      r4rk1/1pp2ppp/p3p3/2b1P3/5P2/2PB1b1P/P1P4P/R1B...      blitz  ...   \n",
      "...                                                  ...        ...  ...   \n",
      "13112  r1bq1b2/3pk3/npp1p1B1/p3P1Q1/3P4/2N5/PPP2PPP/2...      rapid  ...   \n",
      "13113        rkb5/pp6/2pQ4/8/8/2P1BN2/q4PPP/3RKB1R b K -     bullet  ...   \n",
      "13114  2kr1bN1/ppp2p1p/2q1p1p1/3pB3/1n1PP3/2N2P2/PPP3...      rapid  ...   \n",
      "13115                  2r5/4qp1p/8/3K1pPP/k7/8/8/8 b - -      rapid  ...   \n",
      "13116                 6k1/8/1p3r2/4n3/8/8/5q2/1r5K w - -      rapid  ...   \n",
      "\n",
      "      black.rating  black.result  \\\n",
      "0             1636    checkmated   \n",
      "1             1647           win   \n",
      "2             1597      resigned   \n",
      "3             1650    checkmated   \n",
      "4             1639           win   \n",
      "...            ...           ...   \n",
      "13112          632    checkmated   \n",
      "13113          830    checkmated   \n",
      "13114          842      resigned   \n",
      "13115          950           win   \n",
      "13116          845           win   \n",
      "\n",
      "                                           black.@id black.username  \\\n",
      "0          https://api.chess.com/pub/player/owej9023       owej9023   \n",
      "1         https://api.chess.com/pub/player/rajjohari      rajjohari   \n",
      "2      https://api.chess.com/pub/player/hiteshks2000   hiteshks2000   \n",
      "3          https://api.chess.com/pub/player/owej9023       owej9023   \n",
      "4           https://api.chess.com/pub/player/lgn0red        lgn0red   \n",
      "...                                              ...            ...   \n",
      "13112    https://api.chess.com/pub/player/cloudyitch     CloudyItch   \n",
      "13113      https://api.chess.com/pub/player/owej9023       owej9023   \n",
      "13114     https://api.chess.com/pub/player/vingienzo      vingienzo   \n",
      "13115       https://api.chess.com/pub/player/remy332        Remy332   \n",
      "13116      https://api.chess.com/pub/player/owej9023       owej9023   \n",
      "\n",
      "                                 black.uuid accuracies.white  \\\n",
      "0      4b1cf0e4-3122-11eb-97dd-95e88a3be4a6              NaN   \n",
      "1      c00ce7e2-0d59-11e7-8026-000000000000              NaN   \n",
      "2      d59a1abe-e5db-11e4-800e-000000000000              NaN   \n",
      "3      4b1cf0e4-3122-11eb-97dd-95e88a3be4a6              NaN   \n",
      "4      10f33a18-0a07-11ec-be06-213d7c63d77d              NaN   \n",
      "...                                     ...              ...   \n",
      "13112  e83dc1e6-39dd-11eb-b478-0f071c3bab9f              NaN   \n",
      "13113  4b1cf0e4-3122-11eb-97dd-95e88a3be4a6        21.642376   \n",
      "13114  741fa142-1dc1-11e9-805c-000000000000              NaN   \n",
      "13115  a680595e-3725-11eb-b03e-59fce206923a              NaN   \n",
      "13116  4b1cf0e4-3122-11eb-97dd-95e88a3be4a6              NaN   \n",
      "\n",
      "       accuracies.black start_time current_elo opponent_elo  \n",
      "0                   NaN        NaN        1636         1740  \n",
      "1                   NaN        NaN        1653         1647  \n",
      "2                   NaN        NaN        1660         1597  \n",
      "3                   NaN        NaN        1650         1569  \n",
      "4                   NaN        NaN        1642         1639  \n",
      "...                 ...        ...         ...          ...  \n",
      "13112               NaN        NaN         783          632  \n",
      "13113          3.957754        NaN         830          979  \n",
      "13114               NaN        NaN         848          842  \n",
      "13115               NaN        NaN         813          950  \n",
      "13116               NaN        NaN         845          699  \n",
      "\n",
      "[13117 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# Function to clean dates\n",
    "def clean_dates(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Desired game types\n",
    "game_types = ['blitz']  # Example: game types to filter by\n",
    "\n",
    "# Chess.com API to fetch game archives\n",
    "chess_username = 'owej9023'  # Replace with the actual username\n",
    "api_url = f\"https://api.chess.com/pub/player/{chess_username}/games/archives\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "# Fetching the archives\n",
    "response = requests.get(api_url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error fetching data. Status code: {response.status_code}\")\n",
    "    print(f\"Response content: {response.text}\")\n",
    "else:\n",
    "    archives = response.json()\n",
    "    if 'archives' not in archives:\n",
    "        print(\"No archives found or unexpected response structure.\")\n",
    "    else:\n",
    "        print(\"Archives fetched successfully.\")\n",
    "\n",
    "# Initialize a list to store combined game data\n",
    "combined_game_data = []\n",
    "\n",
    "# Iterate through each archive URL and fetch the games\n",
    "for archive_url in reversed(archives['archives']):\n",
    "    with urllib.request.urlopen(archive_url) as url:\n",
    "        archive_game = json.load(url)\n",
    "        \n",
    "        # Check if the expected 'games' key exists\n",
    "        if 'games' in archive_game:\n",
    "            combined_game_data.extend(archive_game['games'])  # Add the games to the combined list\n",
    "        else:\n",
    "            print(f\"Warning: No 'games' found in archive {archive_url}\")\n",
    "\n",
    "# After accumulating all game data, normalize and convert to DataFrame\n",
    "game_df = pd.json_normalize(combined_game_data)\n",
    "\n",
    "\n",
    "# Initialize an empty list to store filtered games\n",
    "filtered_lst = []\n",
    "\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, game in game_df.iterrows():\n",
    "    #print(game)\n",
    "    # Apply the filter conditions\n",
    "    if game['time_class'].lower() in ['blitz', 'rapid', 'bullet'] and \\\n",
    "       game['rules'] == 'chess' and \\\n",
    "       game['rated']:\n",
    "        # Add the game to the filtered list if it meets the conditions\n",
    "        filtered_lst.append(game.to_dict())  # Convert the game row to a dictionary\n",
    "# Create a DataFrame from the filtered games list\n",
    "filtered_df = pd.json_normalize(filtered_lst)\n",
    "\n",
    "chess_username = \"owej9023\"\n",
    "\n",
    "# Add current_elo and opponent_elo columns to the DataFrame\n",
    "filtered_df['current_elo'] = None\n",
    "filtered_df['opponent_elo'] = None\n",
    "\n",
    "# Assign values for games where the user plays as white\n",
    "filtered_df.loc[\n",
    "    filtered_df['white.username'] == chess_username, \n",
    "    ['current_elo', 'opponent_elo']\n",
    "] = filtered_df.loc[\n",
    "    filtered_df['white.username'] == chess_username, \n",
    "    ['white.rating', 'black.rating']\n",
    "].values\n",
    "\n",
    "# Assign values for games where the user plays as black\n",
    "filtered_df.loc[\n",
    "    filtered_df['black.username'] == chess_username, \n",
    "    ['current_elo', 'opponent_elo']\n",
    "] = filtered_df.loc[\n",
    "    filtered_df['black.username'] == chess_username, \n",
    "    ['black.rating', 'white.rating']\n",
    "].values\n",
    "filtered_data = filtered_df\n",
    "for value in filtered_data['']\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef45cae-e71c-423a-9047-1a7a8db41d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_game_data(pgn_str):\n",
    "    \"\"\"\n",
    "    Extract relevant game data (metadata, moves, and timestamps) from a PGN string.\n",
    "    \n",
    "    :param pgn_str: A string containing a PGN game.\n",
    "    :return: A dictionary with extracted game data.\n",
    "    \"\"\"\n",
    "    # Extract game headers (metadata)\n",
    "    header_pattern = r'\\[([A-Za-z]+)\\s+\"([^\"]+)\"\\]'\n",
    "    headers = re.findall(header_pattern, pgn_str)\n",
    "    game_info = {header[0]: header[1] for header in headers}\n",
    "    \n",
    "    # Ensure the 'Termination' field is extracted (if present in the header)\n",
    "    if \"Termination\" not in game_info:\n",
    "        game_info[\"Termination\"] = \"\"\n",
    "\n",
    "    # Extract player ratings, defaulting to empty string if not found\n",
    "    game_info[\"WhiteElo\"] = game_info.get(\"WhiteElo\", \"\")\n",
    "    game_info[\"BlackElo\"] = game_info.get(\"BlackElo\", \"\")\n",
    "    \n",
    "    # Extract moves and timestamps using the provided regex patterns\n",
    "    def extract_moves_and_timestamps(pgn):\n",
    "        # Regex patterns for moves and timestamps\n",
    "        move_pattern = r\"(\\d+\\.\\s(?:O-O(?:-O)?|\\w+)(?:=[QRBN])?|\\d+\\.\\.\\.\\s(?:O-O(?:-O)?|\\w+)(?:=[QRBN])?)\"\n",
    "        timestamp_pattern = r\"\\[%clk\\s([\\d:.]+)\\]\"\n",
    "\n",
    "        # Extract moves and timestamps\n",
    "        moves = re.findall(move_pattern, pgn)\n",
    "        timestamps = re.findall(timestamp_pattern, pgn)\n",
    "\n",
    "        # Check for mismatched lengths\n",
    "        if len(moves) != len(timestamps):\n",
    "            print(\"Warning: Moves and timestamps lengths do not match!\")\n",
    "        \n",
    "        return {\"moves\": moves, \"timestamps\": timestamps}\n",
    "    \n",
    "    # Get moves and timestamps\n",
    "    move_data = extract_moves_and_timestamps(pgn_str)\n",
    "    \n",
    "    # Separate columns for moves and timestamps\n",
    "    game_info[\"Moves\"] = move_data[\"moves\"]\n",
    "    game_info[\"Timestamps\"] = move_data[\"timestamps\"]\n",
    "    \n",
    "    return game_info\n",
    "\n",
    "# Initialize empty lists to store each value\n",
    "value1_list = []\n",
    "value2_list = []\n",
    "\n",
    "# Iterate over each value in the filtered_data['pgn'] and extract data\n",
    "for value in filtered_data['pgn']:\n",
    "    # Assuming x is a dictionary with keys like 'Moves' and 'Timestamps'\n",
    "    x = extract_game_data(str(value))\n",
    "    \n",
    "    # Ensure that x contains 'Moves' and 'Timestamps' before processing\n",
    "    if 'Moves' in x and 'Timestamps' in x:\n",
    "        # Extract values for 'Moves' and 'Timestamps'\n",
    "        value1_list.append(x['Moves'])\n",
    "        value2_list.append(x['Timestamps'])\n",
    "    else:\n",
    "        # Append None if keys are not found\n",
    "        value1_list.append(None)\n",
    "        value2_list.append(None)\n",
    "\n",
    "# Add the extracted values as new columns in the DataFrame\n",
    "filtered_data['Moves'] = value1_list\n",
    "filtered_data['Timestamps'] = value2_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735d68b6-588e-48a1-8673-9e8d712134e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in filtered_data['Moves']:\n",
    "    if len(x) != len(filtered_data['Timestamps'][count]):\n",
    "        print(count)\n",
    "        count+=1\n",
    "    else:\n",
    "        count +=1\n",
    "        #print('pass' + str(count))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b375964d-00d5-4d94-8431-2587a868c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import chess\n",
    "import chess.engine\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_moves_with_stockfish(moves, stockfish_path):\n",
    "    \"\"\"\n",
    "    Analyze chess moves using Stockfish and return the evaluation for each move.\n",
    "    \n",
    "    Args:\n",
    "        moves (list): List of moves in SAN (Standard Algebraic Notation), e.g., ['1. d4', '1... d5', ...]\n",
    "        stockfish_path (str): Path to the Stockfish engine binary.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of evaluation scores after each move.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start the Stockfish engine\n",
    "    with chess.engine.SimpleEngine.popen_uci(stockfish_path) as engine:\n",
    "        # Initialize a list to store scores\n",
    "        scores = []\n",
    "\n",
    "        # Create a new chess board\n",
    "        board = chess.Board()\n",
    "\n",
    "        # Loop over each move in the list\n",
    "        for move in moves:\n",
    "            # Strip the move number and ellipsis (e.g., \"1. d4\" -> \"d4\", \"1... d5\" -> \"d5\")\n",
    "            move_san = move.split(\" \")[-1].strip()  # Extract just the move part (e.g., \"d4\", \"d5\")\n",
    "            #print(move)\n",
    "            if not move_san:\n",
    "                continue  # Skip empty moves (if any)\n",
    "\n",
    "            try:\n",
    "                # Make the move on the board\n",
    "                board.push_san(move_san)\n",
    "                # Evaluate the position after the move\n",
    "                info = engine.analyse(board, chess.engine.Limit(depth=5))\n",
    "                score = info[\"score\"].relative.score(mate_score=5000)  # Use a high value for mate\n",
    "                scores.append(score)\n",
    "            except (ValueError, chess.IllegalMoveError):\n",
    "                # If the move is invalid or illegal, append None and skip this move\n",
    "                scores.append(None)\n",
    "\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6eabda-2485-4e48-8a32-7b7748eb0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockfish_path = r\"C:\\Users\\riann\\Downloads\\stockfish\\stockfish-windows-x86-64-avx2.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e225cff-390e-4f41-9d1f-557e0dcc078d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m filtered_data_test\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      6\u001b[0m     moves \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoves\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m analyze_moves_with_stockfish(moves, stockfish_path)  \u001b[38;5;66;03m# Pass individual 'moves'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     test\u001b[38;5;241m.\u001b[39mappend(analysis)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Assign the analysis results to a new column\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36manalyze_moves_with_stockfish\u001b[1;34m(moves, stockfish_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mAnalyze chess moves using Stockfish and return the evaluation for each move.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    list: List of evaluation scores after each move.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Start the Stockfish engine\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m chess\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mSimpleEngine\u001b[38;5;241m.\u001b[39mpopen_uci(stockfish_path) \u001b[38;5;28;01mas\u001b[39;00m engine:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Initialize a list to store scores\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Create a new chess board\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\site-packages\\chess\\engine.py:3054\u001b[0m, in \u001b[0;36mSimpleEngine.popen_uci\u001b[1;34m(cls, command, timeout, debug, setpgrp, **popen_args)\u001b[0m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpopen_uci\u001b[39m(\u001b[38;5;28mcls\u001b[39m, command: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;241m*\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m, debug: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, setpgrp: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_args: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SimpleEngine:\n\u001b[0;32m   3050\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;124;03m    Spawns and initializes a UCI engine.\u001b[39;00m\n\u001b[0;32m   3052\u001b[0m \u001b[38;5;124;03m    Returns a :class:`~chess.engine.SimpleEngine` instance.\u001b[39;00m\n\u001b[0;32m   3053\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3054\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mpopen(UciProtocol, command, timeout\u001b[38;5;241m=\u001b[39mtimeout, debug\u001b[38;5;241m=\u001b[39mdebug, setpgrp\u001b[38;5;241m=\u001b[39msetpgrp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_args)\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\site-packages\\chess\\engine.py:3046\u001b[0m, in \u001b[0;36mSimpleEngine.popen\u001b[1;34m(cls, Protocol, command, timeout, debug, setpgrp, **popen_args)\u001b[0m\n\u001b[0;32m   3043\u001b[0m         simple_engine\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   3044\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m simple_engine\u001b[38;5;241m.\u001b[39mshutdown_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m-> 3046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_in_background(background, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (command=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, debug\u001b[38;5;241m=\u001b[39mdebug)\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\site-packages\\chess\\engine.py:201\u001b[0m, in \u001b[0;36mrun_in_background\u001b[1;34m(coroutine, name, debug, _policy_lock)\u001b[0m\n\u001b[0;32m    198\u001b[0m         future\u001b[38;5;241m.\u001b[39mset_exception(exc)\n\u001b[0;32m    200\u001b[0m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39mbackground, name\u001b[38;5;241m=\u001b[39mname)\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\site-packages\\chess\\engine.py:195\u001b[0m, in \u001b[0;36mrun_in_background.<locals>.background\u001b[1;34m()\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackground\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mrun(coroutine(future))\n\u001b[0;32m    196\u001b[0m         future\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\runners.py:118\u001b[0m, in \u001b[0;36mRunner.run\u001b[1;34m(self, coro, context)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interrupt_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mrun_until_complete(task)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interrupt_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\base_events.py:653\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\site-packages\\chess\\engine.py:3034\u001b[0m, in \u001b[0;36mSimpleEngine.popen.<locals>.background\u001b[1;34m(future)\u001b[0m\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackground\u001b[39m(future: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture[SimpleEngine]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3034\u001b[0m     transport, protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Protocol\u001b[38;5;241m.\u001b[39mpopen(command, setpgrp\u001b[38;5;241m=\u001b[39msetpgrp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_args)\n\u001b[0;32m   3035\u001b[0m     threading\u001b[38;5;241m.\u001b[39mcurrent_thread()\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (pid=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransport\u001b[38;5;241m.\u001b[39mget_pid()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3036\u001b[0m     simple_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(transport, protocol, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\site-packages\\chess\\engine.py:1320\u001b[0m, in \u001b[0;36mProtocol.popen\u001b[1;34m(cls, command, setpgrp, **popen_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m         \u001b[38;5;66;03m# Unix.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m         popen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_new_session\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39msubprocess_exec(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39mcommand, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_args)\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\base_events.py:1694\u001b[0m, in \u001b[0;36mBaseEventLoop.subprocess_exec\u001b[1;34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1692\u001b[0m     debug_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecute program \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprogram\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_subprocess(debug_log, stdin, stdout, stderr)\n\u001b[1;32m-> 1694\u001b[0m transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_subprocess_transport(\n\u001b[0;32m   1695\u001b[0m     protocol, popen_args, \u001b[38;5;28;01mFalse\u001b[39;00m, stdin, stdout, stderr,\n\u001b[0;32m   1696\u001b[0m     bufsize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug \u001b[38;5;129;01mand\u001b[39;00m debug_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1698\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, debug_log, transport)\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\windows_events.py:399\u001b[0m, in \u001b[0;36mProactorEventLoop._make_subprocess_transport\u001b[1;34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_subprocess_transport\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol, args, shell,\n\u001b[0;32m    396\u001b[0m                                      stdin, stdout, stderr, bufsize,\n\u001b[0;32m    397\u001b[0m                                      extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    398\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[1;32m--> 399\u001b[0m     transp \u001b[38;5;241m=\u001b[39m _WindowsSubprocessTransport(\u001b[38;5;28mself\u001b[39m, protocol, args, shell,\n\u001b[0;32m    400\u001b[0m                                          stdin, stdout, stderr, bufsize,\n\u001b[0;32m    401\u001b[0m                                          waiter\u001b[38;5;241m=\u001b[39mwaiter, extra\u001b[38;5;241m=\u001b[39mextra,\n\u001b[0;32m    402\u001b[0m                                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\base_subprocess.py:36\u001b[0m, in \u001b[0;36mBaseSubprocessTransport.__init__\u001b[1;34m(self, loop, protocol, args, shell, stdin, stdout, stderr, bufsize, waiter, extra, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Create the child process: set the _proc attribute\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start(args\u001b[38;5;241m=\u001b[39margs, shell\u001b[38;5;241m=\u001b[39mshell, stdin\u001b[38;5;241m=\u001b[39mstdin, stdout\u001b[38;5;241m=\u001b[39mstdout,\n\u001b[0;32m     37\u001b[0m                 stderr\u001b[38;5;241m=\u001b[39mstderr, bufsize\u001b[38;5;241m=\u001b[39mbufsize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\windows_events.py:921\u001b[0m, in \u001b[0;36m_WindowsSubprocessTransport._start\u001b[1;34m(self, args, shell, stdin, stdout, stderr, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, shell, stdin, stdout, stderr, bufsize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc \u001b[38;5;241m=\u001b[39m windows_utils\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[0;32m    922\u001b[0m         args, shell\u001b[38;5;241m=\u001b[39mshell, stdin\u001b[38;5;241m=\u001b[39mstdin, stdout\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr,\n\u001b[0;32m    923\u001b[0m         bufsize\u001b[38;5;241m=\u001b[39mbufsize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(f):\n\u001b[0;32m    926\u001b[0m         returncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39mpoll()\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\asyncio\\windows_utils.py:153\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, stdin, stdout, stderr, **kwds)\u001b[0m\n\u001b[0;32m    151\u001b[0m     stderr_wfd \u001b[38;5;241m=\u001b[39m stderr\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(args, stdin\u001b[38;5;241m=\u001b[39mstdin_rfd, stdout\u001b[38;5;241m=\u001b[39mstdout_wfd,\n\u001b[0;32m    154\u001b[0m                      stderr\u001b[38;5;241m=\u001b[39mstderr_wfd, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m (stdin_wh, stdout_rh, stderr_rh):\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\Downloads\\ana\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "filtered_data_test = filtered_data.iloc[0:3]\n",
    "test = []\n",
    "\n",
    "# Iterate over each row in filtered_data_test and analyze the moves\n",
    "for index, row in filtered_data_test.iterrows():\n",
    "    moves = row[\"Moves\"]\n",
    "    \n",
    "    analysis = analyze_moves_with_stockfish(moves, stockfish_path)  # Pass individual 'moves'\n",
    "    \n",
    "    test.append(analysis)\n",
    "\n",
    "# Assign the analysis results to a new column\n",
    "filtered_data_test['Stockfish Analysis'] = test\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "filtered_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99343c-4222-42db-add7-117dbd032740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "filtered_data_test = filtered_data.iloc[0:3]\n",
    "test = []\n",
    "\n",
    "# Use tqdm to wrap your loop for progress bar\n",
    "for index, row in tqdm(filtered_data.iterrows(), total=filtered_data.shape[0], desc=\"Analyzing Moves\"):\n",
    "    moves = row[\"Moves\"]\n",
    "    \n",
    "    # Analyze the moves with Stockfish\n",
    "    analysis = analyze_moves_with_stockfish(moves, stockfish_path)  # Pass individual 'moves'\n",
    "    \n",
    "    test.append(analysis)\n",
    "\n",
    "# Assign the analysis results to a new column\n",
    "filtered_data['Stockfish Analysis'] = test\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "filtered_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f689e0-5d53-4d61-be5b-7450f85b4340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filtered_data.to_csv('filtered_data_with_analysis.csv', index=False)\n",
    "#need a way to turn all these lists into individual values\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import ast\n",
    "\n",
    "filtered_data = pd.read_csv(\"filtered_data_with_analysis.csv\") \n",
    "filtered_data['Moves'] = filtered_data['Moves'].apply(ast.literal_eval)\n",
    "filtered_data_exploded = filtered_data.explode('Moves', ignore_index=True)\n",
    "filtered_data_exploded.to_csv('filtered_data_with_analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d05115-8438-4b33-8e5c-d74a5678d1e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('filtered_data_with_analysis.csv')\n",
    "\n",
    "# Set output directory\n",
    "output_dir = 'C:/Users/19258/Downloads/parquet'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Ensure all relevant columns contain actual lists\n",
    "for col in ['Moves', 'Timestamps', 'Stockfish Analysis']:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Initialize chunk index for file naming\n",
    "chunk_index = 0\n",
    "\n",
    "# Process each row to minimize memory usage\n",
    "for idx, row in df.iterrows():\n",
    "    # Access the values in the current row directly\n",
    "    moves_list = row['Moves']\n",
    "    timestamps_list = row['Timestamps']\n",
    "    stockfish_list = row['Stockfish Analysis']\n",
    "    \n",
    "    # Debug: Print the lengths of the lists\n",
    "    moves_len = len(moves_list)\n",
    "    timestamps_len = len(timestamps_list)\n",
    "    stockfish_len = len(stockfish_list)\n",
    "    \n",
    "    print(f\"Row {idx} - Moves length: {moves_len}, Timestamps length: {timestamps_len}, Stockfish Analysis length: {stockfish_len}\")\n",
    "\n",
    "    # Ensure all columns have equal length\n",
    "    if not (moves_len == timestamps_len == stockfish_len):\n",
    "        print(f\"Skipping row {idx} because column lengths don't match!\")\n",
    "        continue  # Skip this row if lengths don't match\n",
    "\n",
    "    # Create a DataFrame where each column is exploded separately\n",
    "    exploded_df = pd.DataFrame({\n",
    "        'Moves': moves_list,\n",
    "        'Timestamps': timestamps_list,\n",
    "        'Stockfish Analysis': stockfish_list\n",
    "    })\n",
    "\n",
    "    # Check how many rows after explosion\n",
    "    print(f\"After exploding, row {idx} has {len(exploded_df)} rows\")\n",
    "\n",
    "    # Save exploded data to Parquet incrementally using pandas\n",
    "    file_name = f\"chunk_{chunk_index + 1}_exploded.parquet\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Writing to Parquet using pandas and fastparquet\n",
    "    exploded_df.to_parquet(file_path, engine='fastparquet')\n",
    "\n",
    "    print(f\"Saved exploded data to {file_name}\")\n",
    "    chunk_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c72e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('filtered_data_with_analysis.csv')\n",
    "\n",
    "# Set output directory\n",
    "output_dir = 'C:/Users/19258/Downloads/parquet'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Ensure all relevant columns contain actual lists\n",
    "for col in ['Moves', 'Timestamps', 'Stockfish Analysis']:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Initialize chunk index for file naming\n",
    "chunk_index = 0\n",
    "\n",
    "# Process each row to minimize memory usage\n",
    "for idx, row in df.iterrows():\n",
    "    # Access the values in the current row directly\n",
    "    moves_list = row['Moves']\n",
    "    timestamps_list = row['Timestamps']\n",
    "    stockfish_list = row['Stockfish Analysis']\n",
    "    \n",
    "    # Debug: Print the lengths of the lists\n",
    "    #moves_len = len(moves_list)\n",
    "    #timestamps_len = len(timestamps_list)\n",
    "    #stockfish_len = len(stockfish_list)\n",
    "    \n",
    "    #print(f\"Row {idx} - Moves length: {moves_len}, Timestamps length: {timestamps_len}, Stockfish Analysis length: {stockfish_len}\")\n",
    "\n",
    "    # Ensure all columns have equal length\n",
    "    if not (moves_len == timestamps_len == stockfish_len):\n",
    "        print(f\"Skipping row {idx} because column lengths don't match!\")\n",
    "        continue  # Skip this row if lengths don't match\n",
    "\n",
    "    # Create a DataFrame for the other columns (non-exploded columns)\n",
    "    other_columns = row.drop(['Moves', 'Timestamps', 'Stockfish Analysis'])\n",
    "\n",
    "    # Create a DataFrame where the exploded columns are aligned with other columns\n",
    "    exploded_df = pd.DataFrame({\n",
    "        'Moves': moves_list,\n",
    "        'Timestamps': timestamps_list,\n",
    "        'Stockfish Analysis': stockfish_list\n",
    "    })\n",
    "    \n",
    "    # Now, repeat the other columns (non-exploded) to match the exploded rows\n",
    "    for col in other_columns.index:\n",
    "        exploded_df[col] = other_columns[col]\n",
    "\n",
    "    # Check how many rows after explosion\n",
    "    #print(f\"After exploding, row {idx} has {len(exploded_df)} rows\")\n",
    "\n",
    "    # Save exploded data to Parquet incrementally using pandas\n",
    "    file_name = f\"chunk_{chunk_index + 1}_exploded.parquet\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Writing to Parquet using pandas and fastparquet\n",
    "    exploded_df.to_parquet(file_path, engine='fastparquet')\n",
    "\n",
    "    #print(f\"Saved exploded data to {file_name}\")\n",
    "    chunk_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d0990-deef-4c70-b633-84c5f8918f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory where the Parquet files are saved\n",
    "output_dir = 'C:/Users/19258/Downloads/parquet'\n",
    "\n",
    "\n",
    "# List all Parquet files in the output directory\n",
    "parquet_files = [f for f in os.listdir(output_dir) if f.endswith('.parquet')]\n",
    "\n",
    "# List to store DataFrame chunks\n",
    "df_list = []\n",
    "\n",
    "# Load each Parquet file and append it to the list\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    \n",
    "    # Read the Parquet file into a PyArrow Table\n",
    "    table = pq.read_table(file_path)\n",
    "    \n",
    "    # Convert the PyArrow Table to a pandas DataFrame\n",
    "    df_chunk = table.to_pandas()\n",
    "    \n",
    "    # Append the chunk to the list\n",
    "    df_list.append(df_chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single DataFrame\n",
    "df_full = pd.concat(df_list, ignore_index=True)\n",
    "#print(len(df_full))\n",
    "\n",
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db9ca9-2033-4f1f-be86-90cc5b2765f9",
   "metadata": {},
   "source": [
    "Fully Filter the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041eb5f3-4cd4-4726-999e-22726501daa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def time_to_seconds(time_str):\n",
    "    # Split the time string into hours, minutes, and seconds\n",
    "    parts = time_str.split(':')\n",
    "    hours = int(parts[0])  # Always present\n",
    "    minutes = int(parts[1])  # Always present\n",
    "    seconds = parts[2]  # Can have decimal points or not\n",
    "    \n",
    "    # If seconds contains a decimal, split it into seconds and tenths\n",
    "    if '.' in seconds:\n",
    "        seconds, tenths = map(int, seconds.split('.'))\n",
    "    else:\n",
    "        seconds = int(seconds)\n",
    "        tenths = 0  # Default to 0 if no tenths are present\n",
    "\n",
    "    # Calculate total seconds\n",
    "    total_seconds = (hours * 3600) + (minutes * 60) + seconds + (tenths / 10)\n",
    "    return total_seconds\n",
    "\n",
    "# Apply the time_to_seconds function to the 'Timestamps' column\n",
    "result_df['Timestamps'] = result_df['Timestamps'].apply(time_to_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8cfb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the data is processed except for strings like 180+2 or 600+30\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Ensure all target columns are numeric\n",
    "result_df[\"current_elo\"] = pd.to_numeric(result_df[\"current_elo\"], errors=\"coerce\")\n",
    "result_df[\"Moves\"] = pd.to_numeric(result_df[\"Moves\"], errors=\"coerce\")\n",
    "result_df[\"time_class\"] = pd.to_numeric(result_df[\"time_class\"], errors=\"coerce\")\n",
    "\n",
    "# Handle NaN values (e.g., replace with 0 or mean of the column)\n",
    "result_df.fillna(0, inplace=True)\n",
    "\n",
    "# Re-define the target\n",
    "y = result_df[[\"current_elo\", \"Moves\"]].to_numpy()\n",
    "\n",
    "# Encode \"Move\" column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "result_df['Moves'] = label_encoder.fit_transform(result_df['Moves'].astype(str))  # Convert moves to numeric\n",
    "\n",
    "# Define features\n",
    "features = [\"time_class\",\"opponent_elo\", \"current_elo\", \n",
    "            \"Timestamps\", \"Moves\", \"Stockfish Analysis\", \"time_control\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c554c7-8987-4992-ad36-074c16ae4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define a function to safely evaluate expressions\n",
    "def safe_eval(value):\n",
    "    try:\n",
    "        return float(eval(value))  # Evaluate the expression and convert to float\n",
    "    except:\n",
    "        return np.nan  # Return NaN if the evaluation fails\n",
    "\n",
    "# Apply the function to the 'features' column\n",
    "result_df[features] = result_df[features].applymap(safe_eval)\n",
    "\n",
    "# Now normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(result_df[features].to_numpy())  # Normalized feature matrix\n",
    "\n",
    "# Define multi-output target\n",
    "y = result_df[[\"current_elo\", \"Moves\"]].to_numpy()  # Multi-output target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Output shapes for debugging\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3f309-6f41-48a0-8fdb-c997603d11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Device setup (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create DataLoader for efficient batching\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChessNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ChessNN, self).__init__()\n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)         # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(64, 2)           # Output layer (2 predictions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU activation\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)          # Output layer (no activation for regression)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "model = ChessNN(X_train.shape[1]).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()  # For regression\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        # Move batch to GPU\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = loss_fn(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(X_test_tensor).cpu().numpy()  # Move to CPU for numpy conversion\n",
    "    pred_current_elo = output[:, 0]\n",
    "    pred_time_control = output[:, 1]\n",
    "\n",
    "    actual_current_elo = y_test[:, 0]\n",
    "    actual_time_control = y_test[:, 1]\n",
    "\n",
    "    # Metrics for current_elo\n",
    "    mae_elo = mean_absolute_error(actual_current_elo, pred_current_elo)\n",
    "    rmse_elo = mean_squared_error(actual_current_elo, pred_current_elo, squared=False)\n",
    "    r2_elo = r2_score(actual_current_elo, pred_current_elo)\n",
    "    print(f\"Current Elo MAE: {mae_elo}, RMSE: {rmse_elo}, R^2: {r2_elo}\")\n",
    "\n",
    "    # Metrics for time_control\n",
    "    mae_tc = mean_absolute_error(actual_time_control, pred_time_control)\n",
    "    rmse_tc = mean_squared_error(actual_time_control, pred_time_control, squared=False)\n",
    "    r2_tc = r2_score(actual_time_control, pred_time_control)\n",
    "    print(f\"Move MAE: {mae_tc}, RMSE: {rmse_tc}, R^2: {r2_tc}\")\n",
    "\n",
    "    # Combine results\n",
    "    test_game_numbers = result_df.loc[X_test[:, -1].astype(int), 'game_number']\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Game_Number\": test_game_numbers,\n",
    "        \"Predicted_Current_Elo\": pred_current_elo,\n",
    "        \"Actual_Current_Elo\": actual_current_elo,\n",
    "        \"Predicted Move\": pred_time_control,\n",
    "        \"Actual_move\": actual_time_control\n",
    "    }).drop_duplicates(subset=[\"Game_Number\"])\n",
    "\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095a296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a6a92b5-36ee-4b5e-839e-8adcc03ef463",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
